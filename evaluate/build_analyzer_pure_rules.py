import re
import json
import os
from tqdm import tqdm
from datetime import datetime
import sys
from typing import Dict, List, Tuple, Set 
def parse_log_content(log_content):
    """è§£æåŒ…å«<phase>ã€<path>å’Œ<error>æ ‡ç­¾çš„æ—¥å¿—å†…å®¹"""
    phase_pattern = r'<phase>(.*?)<phase>'
    path_pattern = r'<path>(.*?)<path>'
    error_pattern = r'<error>(.*?)<error>'

    phase = re.search(phase_pattern, log_content)
    path = re.search(path_pattern, log_content)
    error = re.search(error_pattern, log_content)

    phase_content = phase.group(1) if phase else None
    path_content = path.group(1) if path else None
    error_content = error.group(1) if error else None

    return {
        'phase': phase_content,
        'path': path_content,
        'error': error_content
    }

def extract_original_path(full_path):
    """ä»ä¿®å¤æ–‡ä»¶è·¯å¾„æå–åŸå§‹æ–‡ä»¶è·¯å¾„"""
    parts = full_path.split('/')
    
    if 'repair_result' in parts:
        repair_idx = parts.index('repair_result')
        original_parts = parts[:repair_idx]
        
        for i in range(repair_idx + 1, len(parts)):
            if parts[i] in ['parfum', 'dockercleaner', 'qwen3_235b_hd_LLM', 'msr25_icl_qwen3_235b']:
                continue
            original_parts.append(parts[i])
        
        original_path = '/'.join(original_parts)
        return original_path
    return None

class SimpleErrorClassifier:
    """ç®€åŒ–çš„é”™è¯¯åˆ†ç±»å™¨ - åŸºäºDockerfileæŒ‡ä»¤åŒ¹é…"""
    
    def __init__(self):
        self.classification_stats = {
            'Base image stage errors': 0,
            'Context stage errors': 0, 
            'Command execution stage errors': 0,
            'Environment configuration stage errors': 0,
            'Unknown': 0
        }
    
    def classify_by_phase(self, error_message: str, failed_phase: str) -> Tuple[str, str]:
        """æ ¹æ®æ„å»ºé˜¶æ®µåˆ†ç±»é”™è¯¯"""
        
        if not failed_phase:
            self.classification_stats['Base image stage errors'] += 1
            return "Base image stage errors", f"åŸºç¡€é•œåƒé˜¶æ®µ"
        
        
        # æ¸…ç†é˜¶æ®µä¿¡æ¯
        clean_phase = self._clean_message(failed_phase)
        clean_error = self._clean_message(error_message)

        # ç®€å•æŒ‡ä»¤åŒ¹é… - å…ˆåŒ¹é…å¤§å†™çš„DockerfileæŒ‡ä»¤
        if any(keyword in clean_phase for keyword in ['FROM']):
            self.classification_stats['Base image stage errors'] += 1
            return "Base image stage errors", f"åŸºç¡€é•œåƒé˜¶æ®µ: {clean_phase[:100]}..."

        elif any(keyword in clean_phase for keyword in ['COPY', 'ADD','copy']):
            self.classification_stats['Context stage errors'] += 1
            return "Context stage errors", f"æ„å»ºä¸Šä¸‹æ–‡é˜¶æ®µ: {clean_phase[:100]}..."

        elif any(keyword in clean_phase for keyword in ['RUN']):
            self.classification_stats['Command execution stage errors'] += 1
            return "Command execution stage errors", f"å‘½ä»¤æ‰§è¡Œé˜¶æ®µ: {clean_phase[:100]}..."

        elif any(keyword in clean_phase for keyword in ['ARG', 'ENV', 'WORKDIR', 'USER', 'EXPOSE', 'VOLUME','LABEL']):
            self.classification_stats['Environment configuration stage errors'] += 1
            return "Environment configuration stage errors", f"ç¯å¢ƒé…ç½®é˜¶æ®µ: {clean_phase[:100]}..."

        
        self.classification_stats['Unknown'] += 1
        return "Unknown", f"æ— æ³•åˆ†ç±» - é˜¶æ®µ: {clean_phase[:100]}..."

    def _clean_message(self, message: str) -> str:
        """æ¸…ç†æ¶ˆæ¯ï¼ˆç§»é™¤é¢œè‰²ä»£ç ç­‰ï¼‰"""
        if not message:
            return ""
        ansi_escape = re.compile(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])')
        return ansi_escape.sub('', message).strip()

    def get_classification_stats(self) -> Dict:
        """è·å–åˆ†ç±»ç»Ÿè®¡"""
        return self.classification_stats

def analyze_build_errors_simple(unbuild_path, output_file=None):
    """ç®€åŒ–çš„æ„å»ºé”™è¯¯åˆ†æ"""
    
    if not os.path.exists(unbuild_path):
        print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ - {unbuild_path}")
        return None
    
    with open(unbuild_path, 'r', encoding='utf-8') as file:
        unbuild_content = file.readlines()
    
    classifier = SimpleErrorClassifier()
    analysis_results = []
    
    print("ğŸ”§ å¼€å§‹ç®€åŒ–ç‰ˆæ„å»ºé”™è¯¯åˆ†æ...")
    print("ğŸ“‹ å››ä¸ªæ„å»ºé˜¶æ®µ:")
    stages = [
        "Base image stage errors - FROMæŒ‡ä»¤ã€é•œåƒæ‹‰å–",
        "Context stage errors - COPY/ADDæ–‡ä»¶æ“ä½œ", 
        "Command execution stage errors - RUNå‘½ä»¤æ‰§è¡Œ",
        "Environment configuration stage errors - ç¯å¢ƒé…ç½®"
    ]
    for stage in stages:
        print(f"  {stage}")
    
    for line in tqdm(unbuild_content, desc="åˆ†æé”™è¯¯"):
        line = line.strip()
        if not line:
            print("ç©ºè¡Œ")
            continue
            
        parsed_log = parse_log_content(line)
        if not parsed_log['path'] or not parsed_log['error']:
            print(f"æ— æ³•è§£æçš„æ—¥å¿—è¡Œ: {line}")
            continue

            
        repair_path = parsed_log['path']
        original_path = extract_original_path(repair_path)
        
        # åˆ†ç±»é”™è¯¯
        error_type, reasoning = classifier.classify_by_phase(
            parsed_log['error'], 
            parsed_log['phase']
        )
        
        analysis_result = {
            'original_path': original_path,
            'repair_path': repair_path,
            'error_message': parsed_log['error'],
            'failed_phase': parsed_log['phase'],
            'error_type': error_type,
            'reasoning': reasoning
        }
        analysis_results.append(analysis_result)
    
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶
    if not output_file:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_file = f"simple_analysis.json"
    
    # ä¿å­˜ç»“æœ
    output_data = {
        'classification_summary': classifier.get_classification_stats(),
        'results': analysis_results,
        'analysis_timestamp': datetime.now().isoformat()
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)
    
    # æ‰“å°ç»Ÿè®¡ç»“æœ
    print_simple_summary(classifier, output_file)
    
    return output_data

def print_simple_summary(classifier, output_file):
    """æ‰“å°ç®€åŒ–ç‰ˆç»Ÿè®¡ç»“æœ"""
    stats = classifier.get_classification_stats()
    total_cases = sum(stats.values())
    
    print("\n" + "="*60)
    print("ğŸ“Š ç®€åŒ–ç‰ˆé”™è¯¯åˆ†æç»“æœ")
    print("="*60)
    
    print("\né”™è¯¯ç±»å‹åˆ†å¸ƒ:")
    for error_type, count in stats.items():
        percentage = (count / total_cases * 100) if total_cases > 0 else 0
        print(f"  {error_type:<35}: {count:>3} ({percentage:>5.1f}%)")
    
    classified = total_cases - stats.get('Unknown', 0)
    classified_pct = (classified / total_cases * 100) if total_cases > 0 else 0
    print(f"\nåˆ†ç±»æˆåŠŸç‡: {classified}/{total_cases} ({classified_pct:.1f}%)")
    print(f"ç»“æœæ–‡ä»¶: {output_file}")

def main():
    if len(sys.argv) < 2:
        print("Usage: python simple_analyzer.py unbuild.log [output_file]")
        print("\nç¤ºä¾‹:")
        print("  python simple_analyzer.py /path/to/unbuild.log")
        print("  python simple_analyzer.py /path/to/unbuild.log results.json")
        sys.exit(1)
    
    unbuild_path = sys.argv[1]
    output_file = sys.argv[2] if len(sys.argv) > 2 else None
    
    if not os.path.exists(unbuild_path):
        print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ - {unbuild_path}")
        sys.exit(1)
    
    print(f"ğŸ”§ å¼€å§‹ç®€åŒ–åˆ†æ")
    print(f"è¾“å…¥æ–‡ä»¶: {unbuild_path}")
    if output_file:
        print(f"è¾“å‡ºæ–‡ä»¶: {output_file}")
    
    result = analyze_build_errors_simple(unbuild_path, output_file)

if __name__ == "__main__":
    main()